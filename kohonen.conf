% true oznaczałoby losowanie wag dla neuronów, weights jest wtedy ignorowane
random_weights = true;

% dane wejściowe
input_data = [
 0 1 0  0 1 0  1 1 1;

 1 1 1  0 0 1  0 0 1;

 1 1 0  1 1 0  1 1 0;
 
 0 0 1  0 1 0  1 1 1;
];

global epochs = [1 8000 16000 24000]

global layers = {};

% pierwsza warstwa
% liczba neuronów w warstwie
layers{1}.type='kohonen';
layers{1}.neurons = 4;
layers{1}.row_count = 1;
% funkcja aktywacji
layers{1}.activation_function =@(X) sigmoid(X);
% wartość bias
layers{1}.bias = 0;
% przedział, z którego są losowane wagi
layers{1}.rand_min = 0.0;
layers{1}.rand_max = 0.2;
layers{1}.neighbourhood_width = [0 0 0 0 ];%[7.0 5.0 3.0 1.0];
layers{1}.conscience_coefficient = [1 0.5 0.25 0.125]; %[0 0 0 0];%
layers{1}.learning_coefficient = [0.06 0.03 0.015 0.0075];%[1 0.5 0.3 0.1]%
layers{1}.learn = true;
layers{1}.learn_steps = 32000;
layers{1}.weights = [   0.08921   0.14574   0.25530   0.10202   0.25530   0.40104   0.35732   0.00000   0.25530   0.24775
  			0.33610   0.35355   0.35355   0.35355   0.35355   0.00000   0.35355   0.35355   0.35355   0.35355
   			0.56148   0.05129   0.00839   0.51523   0.00839   0.05968   0.52362   0.00000   0.00839   0.56652
   			0.41902   0.52496   0.01781   0.02940   0.01781   0.54277   0.04721   0.00000   0.01781   0.55435
		    ]
%layers{2}.type='normal';
%layers{2}.neurons=3;
%layers{2}.bias = -1;
%layers{2}.rand_min = -1.0;
%layers{2}.rand_max = 1.0;
%layers{2}.activation_function = @(X) linear(X,1,0);








